{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>Radio</th>\n",
       "      <th>Newspaper</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>230.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>69.2</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>45.1</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>69.3</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>151.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>58.5</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>180.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>58.4</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TV  Radio  Newspaper  Sales\n",
       "0  230.1   37.8       69.2   22.1\n",
       "1   44.5   39.3       45.1   10.4\n",
       "2   17.2   45.9       69.3    9.3\n",
       "3  151.5   41.3       58.5   18.5\n",
       "4  180.8   10.8       58.4   12.9"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Read in the data\n",
    "df = pd.read_csv(\"../data/Advertising.csv\")\n",
    "df.drop(columns=[\"Unnamed: 0\"], inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples:  200\n",
      "Number of features:  3\n"
     ]
    }
   ],
   "source": [
    "# creating samples and features variables\n",
    "number_of_samples, number_of_features = df.shape[0], df.shape[1] - 1 # -1 to exclude the sales. because we are predicting sales\n",
    "print(\"Number of samples: \", number_of_samples)\n",
    "print(\"Number of features: \", number_of_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>Radio</th>\n",
       "      <th>Newspaper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>230.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>69.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>45.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>69.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>151.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>58.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>180.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>58.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TV  Radio  Newspaper\n",
       "0  230.1   37.8       69.2\n",
       "1   44.5   39.3       45.1\n",
       "2   17.2   45.9       69.3\n",
       "3  151.5   41.3       58.5\n",
       "4  180.8   10.8       58.4"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setting X and y\n",
    "X, y = df.drop(\"Sales\", axis=1), df[\"Sales\"] # axis = 1 means column, axis = 0 means row\n",
    "# Convention is using capital X for the features and lowercase y for the response variable\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    22.1\n",
       "1    10.4\n",
       "2     9.3\n",
       "3    18.5\n",
       "4    12.9\n",
       "Name: Sales, dtype: float64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sklearn - typical steps\n",
    "  \n",
    "1. train|test split, sometimes train|val|test split\n",
    "  if we want to hyperparameter evaluate we need to evaluate.\n",
    "2. scaling sometimes required.\n",
    "    - min-max scaling\n",
    "    - standardization\n",
    "    - ...\n",
    "    - scale training data, \n",
    "    - scale test data to the training data --> avoiding data leakage.\n",
    "3. Fit algorithm to training data (Actually training the model).\n",
    "4. Predict test data\n",
    "5. Evaluate\n",
    "\n",
    "recipe for many algorithms"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train|test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in training set:  140  and number of features:  3\n",
      "Number of samples in testing set:  60  and number of features:  3\n"
     ]
    }
   ],
   "source": [
    "# Splitting the data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "print(\"Number of samples in training set: \", X_train.shape[0], \" and number of features: \", X_train.shape[1])\n",
    "print(\"Number of samples in testing set: \", X_test.shape[0], \" and number of features: \", X_test.shape[1])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature scaling\n",
    "Normalization (min-max feature scaling)\n",
    "### $X' = \\frac{X-X_{\\min}}{X_{max}-X_{min}}$\n",
    "\n",
    "Feature standardization\n",
    "### $X' = \\frac{X-\\mu}{\\sigma}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scaled_X_train.min() = 0.0\n",
      "scaled_X_train.max() = 1.0\n",
      "scaled_X_test.min() = 0.005964214711729622\n",
      "scaled_X_test.max() = 1.1302186878727631\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Scaling the data\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "scaler.fit(X_train) # fit the scaler to the training data\n",
    "\n",
    "scaled_X_train = scaler.fit_transform(X_train)\n",
    "scaled_X_test = scaler.transform(X_test)\n",
    "\n",
    "print(f\"{scaled_X_train.min() = }\")\n",
    "print(f\"{scaled_X_train.max() = }\")\n",
    "print(f\"{scaled_X_test.min() = }\")\n",
    "print(f\"{scaled_X_test.max() = }\")\n",
    "# Note: scaled_X_test min and max are not 0 and 1 because we are using the same scaler as the training data\n",
    "# 0 < = scaled_X_train <= 1\n",
    "# 0.005964 <= scaled_X_test <= 1.130218\n",
    "\n",
    "# Note: this type of scaling is very sensitive to outliers because it is based on the min and max values of the data.\n",
    "# it is good practice to remove outliers before scaling the data\n",
    "\n",
    "# Choosing a model or type of scaling is a hyperparameter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((140, 3), (60, 3))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking what scaled_X_train returns\n",
    "scaled_X_train.shape, scaled_X_test.shape # returns a numpy array"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: [13.02832938  9.88465985  0.69237469]\n",
      "Intercept: 2.7418553248528124\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Creating a model\n",
    "model_OLS = LinearRegression() # LinearRegression fits a linear model with coefficients w = (w1, ..., wp) to minimize the residual sum of squares between the observed targets in the dataset, and the targets predicted by the linear approximation.\n",
    "\n",
    "# Fitting the model to the training data\n",
    "model_OLS.fit(scaled_X_train, y_train) # fit the model to the training data\n",
    "\n",
    "print(f\"Parameters: {model_OLS.coef_}\") # beta_1, beta_2, beta_3\n",
    "print(f\"Intercept: {model_OLS.intercept_}\") # beta_0 \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: [11.97674049  9.01777722  1.34945842]\n",
      "Intercept: [3.55935577]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "# Creating a model\n",
    "\n",
    "model_SGD = SGDRegressor(loss= \"squared_error\", max_iter=10000) # fitted by minimizing a regularized empirical loss with SGD\n",
    "model_SGD.fit(scaled_X_train, y_train)\n",
    "\n",
    "print(f\"Parameters: {model_SGD.coef_}\") # beta_1, beta_2, beta_3\n",
    "print(f\"Intercept: {model_SGD.intercept_}\") # beta_0 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.54988164, 0.63709677, 0.52286282]]), 16.9)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sample_features = scaled_X_test[0].reshape(1, -1) #\n",
    "test_sample_label = y_test.values[0] # the actual value of the first sample in the test set\n",
    "test_sample_features, test_sample_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.56539629743484"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting the label of a test sample\n",
    "model_OLS.predict(test_sample_features)[0] # predicted value of the first sample in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.595923854092426"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting with SGD\n",
    "model_SGD.predict(test_sample_features)[0] # predicted value of the first sample in the test set"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean absolute error of OLS: 1.511669222454909\n",
      "Mean absolute error of SGD: 1.5231020384464784\n",
      "Mean squared error of OLS: 3.7967972367152223\n",
      "Mean squared error of SGD: 4.0876225249670926\n",
      "Root mean squared error of OLS: 1.9485372043446392\n",
      "Root mean squared error of SGD: 2.0217869632993217\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Predicting the labels of the test set\n",
    "y_pred_OLS = model_OLS.predict(scaled_X_test)  # important to use the scaled test set\n",
    "y_pred_SGD = model_SGD.predict(scaled_X_test)  # important to use the scaled test set\n",
    "\n",
    "# Calculating the mean absolute error\n",
    "mae_OLS = mean_absolute_error(y_test, y_pred_OLS)\n",
    "mae_SGD = mean_absolute_error(y_test, y_pred_SGD)\n",
    "\n",
    "print(f\"Mean absolute error of OLS: {mae_OLS}\") # OLS is better than SGD because it is closer to 0 (the lower the better)\n",
    "\n",
    "print(f\"Mean absolute error of SGD: {mae_SGD}\")\n",
    "\n",
    "# Calculating the mean squared error\n",
    "mse_OLS = mean_squared_error(y_test, y_pred_OLS) # MSE is lower than SGD. OLS is better than SGD\n",
    "mse_SGD = mean_squared_error(y_test, y_pred_SGD)\n",
    "\n",
    "print(f\"Mean squared error of OLS: {mse_OLS}\")\n",
    "\n",
    "print(f\"Mean squared error of SGD: {mse_SGD}\")\n",
    "\n",
    "# Calculating the root mean squared error\n",
    "rmse_OLS = np.sqrt(mse_OLS) # OLS is better than SGD\n",
    "rmse_SGD = np.sqrt(mse_SGD) \n",
    "\n",
    "print(f\"Root mean squared error of OLS: {rmse_OLS}\")\n",
    "\n",
    "print(f\"Root mean squared error of SGD: {rmse_SGD}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Machine-Learning-Alexander-Andersson-sEvkd_-c",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c35d1dd56d5ab894c470f65fef5acece861691ed222944ff75d018dd827499a8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
