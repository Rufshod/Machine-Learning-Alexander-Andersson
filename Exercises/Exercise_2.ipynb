{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. EDA (*)\n",
    "\n",
    "In the whole exercise, we will work with the \"mpg\" dataset from seaborn dataset. Start by loading dataset \"mpg\" from the ```load_dataset``` method in seaborn module. The goal will be to use linear regression to predict mpg - miles per gallon. \n",
    "\n",
    "&nbsp; a) Start by doing some initial EDA such as info(), describe() and figure out what you want to do with the missing values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sns.load_dataset(\"mpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mpg              25.0\n",
      "cylinders           4\n",
      "displacement     98.0\n",
      "horsepower        NaN\n",
      "weight           2046\n",
      "acceleration     19.0\n",
      "model_year         71\n",
      "origin            usa\n",
      "make             ford\n",
      "model           pinto\n",
      "Name: 32, dtype: object\n",
      "mpg                 21.0\n",
      "cylinders              6\n",
      "displacement       200.0\n",
      "horsepower           NaN\n",
      "weight              2875\n",
      "acceleration        17.0\n",
      "model_year            74\n",
      "origin               usa\n",
      "make                ford\n",
      "model           maverick\n",
      "Name: 126, dtype: object\n",
      "mpg               26.0\n",
      "cylinders            4\n",
      "displacement     108.0\n",
      "horsepower        93.0\n",
      "weight            2391\n",
      "acceleration      15.5\n",
      "model_year          74\n",
      "origin           japan\n",
      "make            subaru\n",
      "model             None\n",
      "Name: 150, dtype: object\n",
      "mpg                     40.9\n",
      "cylinders                  4\n",
      "displacement            85.0\n",
      "horsepower               NaN\n",
      "weight                  1835\n",
      "acceleration            17.3\n",
      "model_year                80\n",
      "origin                europe\n",
      "make                 renault\n",
      "model           lecar deluxe\n",
      "Name: 330, dtype: object\n",
      "mpg                      23.6\n",
      "cylinders                   4\n",
      "displacement            140.0\n",
      "horsepower                NaN\n",
      "weight                   2905\n",
      "acceleration             14.3\n",
      "model_year                 80\n",
      "origin                    usa\n",
      "make                     ford\n",
      "model           mustang cobra\n",
      "Name: 336, dtype: object\n",
      "mpg               32.3\n",
      "cylinders            4\n",
      "displacement      97.0\n",
      "horsepower        67.0\n",
      "weight            2065\n",
      "acceleration      17.8\n",
      "model_year          81\n",
      "origin           japan\n",
      "make            subaru\n",
      "model             None\n",
      "Name: 346, dtype: object\n",
      "mpg                34.5\n",
      "cylinders             4\n",
      "displacement      100.0\n",
      "horsepower          NaN\n",
      "weight             2320\n",
      "acceleration       15.8\n",
      "model_year           81\n",
      "origin           europe\n",
      "make            renault\n",
      "model               18i\n",
      "Name: 354, dtype: object\n",
      "mpg                   23.0\n",
      "cylinders                4\n",
      "displacement         151.0\n",
      "horsepower             NaN\n",
      "weight                3035\n",
      "acceleration          20.5\n",
      "model_year              82\n",
      "origin                 usa\n",
      "make                   amc\n",
      "model           concord dl\n",
      "Name: 374, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Agam\\AppData\\Local\\Temp\\ipykernel_16756\\1975367176.py:3: FutureWarning: In a future version of pandas all arguments of StringMethods.split except for the argument 'pat' will be keyword-only.\n",
      "  df[[\"name\", \"test\"]] = df[\"name\"].str.split(\n"
     ]
    }
   ],
   "source": [
    "# Importing and cleaning data\n",
    "# Adding columns\n",
    "df[[\"name\", \"test\"]] = df[\"name\"].str.split(\n",
    "    \" \", 1, expand=True\n",
    ")  # Creating a new column\n",
    "df.rename(\n",
    "    columns={\"name\": \"make\", \"test\": \"model\"}, inplace=True\n",
    ")  # Renaming columns\n",
    "cars = df  # Creating a new dataframe\n",
    "\n",
    "# Handling spelling mistakes:\n",
    "\n",
    "# Renaming function\n",
    "def func_rename(dataframe, oldname:str,  newname:str):\n",
    "    \"\"\"Function for renaming something in a dataframe, enter the dataframe, oldname and new name. \"\"\"\n",
    "    \n",
    "    return dataframe[\"make\"].replace(oldname, newname, inplace=True) # Renaming and returning the dataframe\n",
    "#   The spelling mistakes were found by manually looking through the data.\n",
    "#   func_rename can be found in the Functions.py file\n",
    "func_rename(cars, \"vw\", \"volkswagen\"), func_rename(cars, \"vokswagen\", \"volkswagen\")\n",
    "func_rename(cars, \"chevy\", \"chevrolet\"), func_rename(cars, \"chevroelt\", \"chevrolet\")\n",
    "func_rename(cars, \"maxda\", \"mazda\"), func_rename(cars, \"toyouta\", \"toyota\")\n",
    "func_rename(cars, \"mercedes-benz\", \"mercedes\"),\n",
    "\n",
    "# Lets check if any data is missing.\n",
    "cars.isna().sum()\n",
    "np.where(cars.isna().any(axis=1))  # Checking for nans.\n",
    "nanlist = [32, 126, 150, 330, 336, 346, 354, 374]  # The indexes for nan values.\n",
    "for i in range(len(nanlist)):\n",
    "    print(cars.iloc[nanlist[i]])  # Simple forloop to print out all nan rows.\n",
    "\n",
    "# Total NaNs in dataframe is 8. 8/len(cars) ~ 2 %\n",
    "# I find it acceptable to drop NaNs due to the value being so low. Would it be higher I would have to fill the data with the mean or ask the client for a complete sample\n",
    "\n",
    "cars.dropna(inplace=True)\n",
    "\n",
    "# I will also be dropping everything that is not numerical\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp; d) Check if there are any columns you might want to drop. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will also be dropping everything that is not numerical\n",
    "cars.drop(\"make\", axis=1, inplace=True)\n",
    "cars.drop(\"model\",axis=1, inplace=True)\n",
    "cars.drop(\"origin\",axis=1, inplace=True)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp; b) Use describe only on those columns that are relevant to get statistical information from. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(count    390.000000\n",
       " mean      23.416667\n",
       " std        7.811030\n",
       " min        9.000000\n",
       " 25%       17.000000\n",
       " 50%       22.450000\n",
       " 75%       29.000000\n",
       " max       46.600000\n",
       " Name: mpg, dtype: float64,\n",
       " count    390.000000\n",
       " mean     104.594872\n",
       " std       38.538599\n",
       " min       46.000000\n",
       " 25%       75.250000\n",
       " 50%       94.500000\n",
       " 75%      128.000000\n",
       " max      230.000000\n",
       " Name: horsepower, dtype: float64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cars[\"mpg\"].describe(), cars[\"horsepower\"].describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp; c) Make some plots on some of the columns that you find interesting.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Train|test split (*)\n",
    "\n",
    "We want to predict the \"mpg\", split up X and y, and perform train|test split using scikit-learn. Choose test_size of 0.2 and random_state 42. Control the shapes of each X_train, X_test, y_train, y_test.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((312, 6), (78, 6), (312,), (78,), (390, 6), (390,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = df.drop(\"mpg\", axis=1), df[\"mpg\"]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape, X.shape, y.shape\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Function for evaluation (*)\n",
    "\n",
    "Create a function for training a regression model, predicting and computing the metrics MAE, MSE, RMSE. It should take in parameters of X_train, X_test, y_train, y_test, model. Now create a linear regression model using scikit-learns ```LinearRegression()``` (OLS normal equation with SVD) and call your function to get metrics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.8225695789275353, 13.252912285875826, 3.6404549558916157)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression, SGDRegressor\n",
    "model = LinearRegression()\n",
    "\n",
    "def eval_func(X_train, X_test, y_train, y_test, model):\n",
    "   \n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    MAE = mean_absolute_error(y_test, y_pred) # LOWER NUMBER BETTER\n",
    "    MSE = mean_squared_error(y_test, y_pred)\n",
    "    RMSE = np.sqrt(MSE)\n",
    "    return MAE, MSE, RMSE\n",
    "\n",
    "eval_func(X_train, X_test, y_train, y_test, model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Compare models (*)\n",
    "\n",
    "Create the following models \n",
    "- Linear regression (SVD)\n",
    "- Linear regression (SVD) with scaled data (feature standardization)\n",
    "- Stochastic gradient descent with scaled data (feature standardization)\n",
    "- Polynomial linear regression with degree 1\n",
    "- Polynomial linear regression with degree 2\n",
    "- Polynomial linear regression with degree 3\n",
    "\n",
    "Make a DataFrame with evaluation metrics and model. Which model performed overall best?\n",
    "\n",
    "<details>\n",
    "\n",
    "<summary>Answer</summary>\n",
    "\n",
    "|      |   Linear regr. SVD |   Linear regr. SVD scaled |   Linear regr. SGD |   Polynom. regr. deg 1 |   Polynom. regr. deg 2 |   Polynom. regr. deg 3 |\n",
    "|:-----|-------------------:|--------------------------:|-------------------:|-----------------------:|-----------------------:|-----------------------:|\n",
    "| mae  |            2.50386 |                   2.50386 |            2.53515 |                2.50386 |                1.98048 |                2.11788 |\n",
    "| mse  |           10.5024  |                  10.5024  |           10.8908  |               10.5024  |                7.41986 |                9.27353 |\n",
    "| rmse |            3.24074 |                   3.24074 |            3.30012 |                3.24074 |                2.72394 |                3.04525 |\n",
    "\n",
    "</details>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LinearRegression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.822570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.252912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.640455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LinearRegression\n",
       "0          2.822570\n",
       "1         13.252912\n",
       "2          3.640455"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linreg = eval_func(X_train, X_test, y_train, y_test, model)\n",
    "\n",
    "model_comp = pd.DataFrame()\n",
    "\n",
    "model_comp[\"LinearRegression\"] = linreg\n",
    "\n",
    "model_comp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.822569578927536, 13.252912285875823, 3.6404549558916153)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Linear regression with scaled data: \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "model = LinearRegression() # with scaled data. \n",
    "\n",
    "def eval_func(X_train, X_test, y_train, y_test, model):\n",
    "   \n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(X_train) # important - use this for training data\n",
    "\n",
    "    scaled_X_train = scaler.transform(X_train)\n",
    "    scaled_X_test = scaler.transform(X_test)\n",
    "\n",
    "    model.fit(scaled_X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(scaled_X_test)\n",
    "    MAE = mean_absolute_error(y_test, y_pred) # LOWER NUMBER BETTER\n",
    "    MSE = mean_squared_error(y_test, y_pred)\n",
    "    RMSE = np.sqrt(MSE)\n",
    "    return MAE, MSE, RMSE\n",
    "\n",
    "eval_func(X_train, X_test, y_train, y_test, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.914174466001833, 14.233837591387768, 3.77277584695775)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stochastic gradient descent with scaled data:\n",
    "model_SGD = SGDRegressor(loss=\"squared_error\", max_iter=10000, random_state= 42, learning_rate=\"adaptive\")\n",
    "\n",
    "def eval_func(X_train, X_test, y_train, y_test, model):\n",
    "   \n",
    "    scaler = MinMaxScaler() #scaler function.\n",
    "    scaler.fit(X_train)\n",
    "\n",
    "    scaled_X_train = scaler.transform(X_train)\n",
    "    scaled_X_test = scaler.transform(X_test)\n",
    "\n",
    "    model_SGD.fit(scaled_X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(scaled_X_test)\n",
    "    MAE = mean_absolute_error(y_test, y_pred) # LOWER NUMBER BETTER\n",
    "    MSE = mean_squared_error(y_test, y_pred)\n",
    "    RMSE = np.sqrt(MSE)\n",
    "    return MAE, MSE, RMSE\n",
    "\n",
    "eval_func(X_train, X_test, y_train, y_test, model_SGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Machine-Learning-Alexander-Andersson-sEvkd_-c",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c35d1dd56d5ab894c470f65fef5acece861691ed222944ff75d018dd827499a8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
